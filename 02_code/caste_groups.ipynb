{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "data = pd.read_csv('/Users/bishmaybarik/Library/CloudStorage/OneDrive-ShivNadarInstitutionofEminence/estimate_inc_risk/01_data/inrisk_data.csv')\n",
    "\n",
    "# Step 2: Filter the data\n",
    "filtered_data = data[\n",
    "    (data['relation_with_hoh'] == 'HOH') &\n",
    "    (data['gender'] == 'M') &\n",
    "    (data['age_yrs'] > 25) &\n",
    "    (data['age_yrs'] < 60)\n",
    "]\n",
    "\n",
    "# Step 3: Combine income variables to calculate total income\n",
    "filtered_data['total_income'] = (\n",
    "    filtered_data['inc_of_mem_frm_all_srcs'] + filtered_data['inc_of_mem_frm_wages']\n",
    ")\n",
    "\n",
    "# Step 4: Retain only rows with positive total_income\n",
    "trimmed_data = filtered_data[filtered_data['total_income'] > 0]\n",
    "\n",
    "# Step 5: Take the log of total income\n",
    "trimmed_data['log_total_income'] = np.log(trimmed_data['total_income'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Step 6: Initialize the interest_soc_group column\n",
    "trimmed_data['interest_soc_group'] = np.nan\n",
    "\n",
    "# Step 7: Replace values based on conditions\n",
    "trimmed_data.loc[trimmed_data['caste_category'] == \"SC\", 'interest_soc_group'] = 1\n",
    "trimmed_data.loc[trimmed_data['caste_category'] == \"ST\", 'interest_soc_group'] = 2\n",
    "trimmed_data.loc[trimmed_data['caste_category'] == \"OBC\", 'interest_soc_group'] = 3\n",
    "trimmed_data.loc[trimmed_data['religion'] == \"Muslim\", 'interest_soc_group'] = 4\n",
    "trimmed_data.loc[\n",
    "    (trimmed_data['religion'] == \"Hindu\") & \n",
    "    (trimmed_data['caste_category'].isin([\"Intermediate Caste\", \"Upper Caste\"])), \n",
    "    'interest_soc_group'\n",
    "] = 5\n",
    "trimmed_data.loc[trimmed_data['interest_soc_group'].isna(), 'interest_soc_group'] = 6\n",
    "\n",
    "# Step 8: Define and apply labels\n",
    "socgroup_labels = {\n",
    "    1: \"SC\",\n",
    "    2: \"ST\",\n",
    "    3: \"OBC\",\n",
    "    4: \"Muslims\",\n",
    "    5: \"Other Hindus\",\n",
    "    6: \"Other Religions\"\n",
    "}\n",
    "\n",
    "trimmed_data['interest_soc_group'] = trimmed_data['interest_soc_group'].astype(int)  # Convert to int for labeling\n",
    "trimmed_data['interest_soc_group_label'] = trimmed_data['interest_soc_group'].map(socgroup_labels)\n",
    "\n",
    "# The `trimmed_data` DataFrame now contains the `interest_soc_group` and its labeled version.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Define social groups\n",
    "social_groups = {\n",
    "    1: \"SC\",\n",
    "    2: \"ST\",\n",
    "    3: \"OBC\",\n",
    "    4: \"Muslims\",\n",
    "    5: \"Other Hindus\",\n",
    "    6: \"Other Religions\"\n",
    "}\n",
    "\n",
    "# Initialize a dictionary to store the results\n",
    "results = {}\n",
    "\n",
    "# Loop over each social group\n",
    "for group, label in social_groups.items():\n",
    "    # Filter the data for the current social group\n",
    "    group_data = trimmed_data[trimmed_data['interest_soc_group'] == group]\n",
    "    \n",
    "    # Step 6: Run OLS to estimate the fixed component (alpha_i)\n",
    "    X = sm.add_constant(group_data['age_yrs'])  # Add constant for intercept\n",
    "    y = group_data['log_total_income']\n",
    "    ols_model = sm.OLS(y, X).fit()\n",
    "    group_data['fitted_values'] = ols_model.fittedvalues\n",
    "    \n",
    "    # Step 7: Calculate residuals\n",
    "    group_data['residuals'] = group_data['log_total_income'] - group_data['fitted_values']\n",
    "    \n",
    "    # Step 8: Estimate variance of alpha (sigma_alpha^2)\n",
    "    sigma_alpha_squared = np.var(group_data['fitted_values'], ddof=1)  # Use ddof=1 for sample variance\n",
    "    \n",
    "    # Step 9: Estimate the transitory income variance (sigma_nu^2)\n",
    "    sigma_nu_squared = np.var(group_data['residuals'], ddof=1)  # Use ddof=1 for sample variance\n",
    "    \n",
    "    # Step 10: Estimate rho (autoregressive parameter)\n",
    "    group_data['lagged_residuals'] = group_data['residuals'].shift(1)\n",
    "    group_data = group_data.dropna()  # Drop rows with NaN due to lag\n",
    "    X_lag = sm.add_constant(group_data['lagged_residuals'])\n",
    "    y_res = group_data['residuals']\n",
    "    ar_model = sm.OLS(y_res, X_lag).fit()\n",
    "    rho = ar_model.params['lagged_residuals']\n",
    "    \n",
    "    # Step 11: Estimate variance of permanent income at t=0 (sigma_y_p0^2)\n",
    "    if abs(rho) < 1:\n",
    "        sigma_y_p0_squared = sigma_alpha_squared / (1 - rho**2)\n",
    "    else:\n",
    "        raise ValueError(\"rho must be less than 1 for the variance formula to hold.\")\n",
    "    \n",
    "    # Step 12: Estimate variance of shock (sigma_xi^2)\n",
    "    shocks = group_data['residuals'] - rho * group_data['lagged_residuals']\n",
    "    sigma_xi_squared = np.var(shocks, ddof=1)  # Use ddof=1 for sample variance\n",
    "    \n",
    "    # Store the results in the dictionary\n",
    "    results[label] = {\n",
    "        'sigma_alpha_squared': sigma_alpha_squared,\n",
    "        'sigma_nu_squared': sigma_nu_squared,\n",
    "        'rho': rho,\n",
    "        'sigma_y_p0_squared': sigma_y_p0_squared,\n",
    "        'sigma_xi_squared': sigma_xi_squared\n",
    "    }\n",
    "\n",
    "# Display the results\n",
    "for label, result in results.items():\n",
    "    print(f\"Results for {label}:\")\n",
    "    print(f\"Variance of alpha (sigma_alpha^2): {result['sigma_alpha_squared']}\")\n",
    "    print(f\"Variance of transitory income (sigma_nu^2): {result['sigma_nu_squared']}\")\n",
    "    print(f\"Autoregressive parameter (rho): {result['rho']}\")\n",
    "    print(f\"Variance of permanent income at t=0 (sigma_y_p0^2): {result['sigma_y_p0_squared']}\")\n",
    "    print(f\"Variance of shock (sigma_xi^2): {result['sigma_xi_squared']}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"/Users/bishmaybarik/Library/CloudStorage/OneDrive-ShivNadarInstitutionofEminence/estimate_inc_risk/03_results/caste_group_results.txt\"\n",
    "\n",
    "# Open the file in write mode\n",
    "with open(output_path, \"w\") as file:\n",
    "    # Loop over the results dictionary and write each group's results\n",
    "    for label, result in results.items():\n",
    "        file.write(f\"Results for {label}:\\n\")\n",
    "        file.write(f\"Variance of alpha (sigma_alpha^2): {result['sigma_alpha_squared']}\\n\")\n",
    "        file.write(f\"Variance of transitory income (sigma_nu^2): {result['sigma_nu_squared']}\\n\")\n",
    "        file.write(f\"Autoregressive parameter (rho): {result['rho']}\\n\")\n",
    "        file.write(f\"Variance of permanent income at t=0 (sigma_y_p0^2): {result['sigma_y_p0_squared']}\\n\")\n",
    "        file.write(f\"Variance of shock (sigma_xi^2): {result['sigma_xi_squared']}\\n\")\n",
    "        file.write(\"-\" * 50 + \"\\n\")\n",
    "        \n",
    "print(f\"Results successfully saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Number of bootstrap iterations\n",
    "n_iterations = 10  # Reduced to 10 iterations\n",
    "n_size = len(trimmed_data)\n",
    "\n",
    "# Define social groups\n",
    "social_groups = {\n",
    "    1: \"SC\",\n",
    "    2: \"ST\",\n",
    "    3: \"OBC\",\n",
    "    4: \"Muslims\",\n",
    "    5: \"Other Hindus\",\n",
    "    6: \"Other Religions\"\n",
    "}\n",
    "\n",
    "# Function to calculate the confidence interval\n",
    "def confidence_interval(data, alpha=0.05):\n",
    "    lower = np.percentile(data, 100 * (alpha / 2))\n",
    "    upper = np.percentile(data, 100 * (1 - alpha / 2))\n",
    "    return lower, upper\n",
    "\n",
    "# Loop over each social group\n",
    "for group, label in social_groups.items():\n",
    "    # Filter data for the current group\n",
    "    group_data = trimmed_data[trimmed_data['interest_soc_group'] == group]\n",
    "    \n",
    "    # Arrays to store bootstrap estimates\n",
    "    sigma_alpha_squared_samples = []\n",
    "    sigma_nu_squared_samples = []\n",
    "    rho_samples = []\n",
    "    sigma_y_p0_squared_samples = []\n",
    "    sigma_xi_squared_samples = []\n",
    "    \n",
    "    # Bootstrapping\n",
    "    for i in range(n_iterations):\n",
    "        # Resample the data with replacement\n",
    "        bootstrap_sample = resample(group_data, n_samples=n_size, replace=True)\n",
    "        \n",
    "        # Step 1: Recalculate total_income and residuals\n",
    "        X_boot = sm.add_constant(bootstrap_sample['age_yrs'])  # Add constant for intercept\n",
    "        y_boot = bootstrap_sample['log_total_income']\n",
    "        ols_model_boot = sm.OLS(y_boot, X_boot).fit()\n",
    "        bootstrap_sample['fitted_values'] = ols_model_boot.fittedvalues\n",
    "        bootstrap_sample['residuals'] = y_boot - bootstrap_sample['fitted_values']\n",
    "        \n",
    "        # Step 2: Variance of alpha (sigma_alpha^2)\n",
    "        sigma_alpha_squared_samples.append(np.var(bootstrap_sample['fitted_values'], ddof=1))\n",
    "        \n",
    "        # Step 3: Variance of transitory income (sigma_nu^2)\n",
    "        sigma_nu_squared_samples.append(np.var(bootstrap_sample['residuals'], ddof=1))\n",
    "        \n",
    "        # Step 4: Autoregressive parameter (rho)\n",
    "        bootstrap_sample['lagged_residuals'] = bootstrap_sample['residuals'].shift(1)\n",
    "        bootstrap_sample = bootstrap_sample.dropna()  # Drop rows with NaN due to lag\n",
    "        X_lag_boot = sm.add_constant(bootstrap_sample['lagged_residuals'])\n",
    "        y_res_boot = bootstrap_sample['residuals']\n",
    "        ar_model_boot = sm.OLS(y_res_boot, X_lag_boot).fit()\n",
    "        rho_samples.append(ar_model_boot.params['lagged_residuals'])\n",
    "        \n",
    "        # Step 5: Variance of permanent income at t=0 (sigma_y_p0^2)\n",
    "        rho_boot = ar_model_boot.params['lagged_residuals']\n",
    "        if abs(rho_boot) < 1:\n",
    "            sigma_y_p0_squared_samples.append(np.var(bootstrap_sample['fitted_values'], ddof=1) / (1 - rho_boot**2))\n",
    "        else:\n",
    "            sigma_y_p0_squared_samples.append(np.nan)  # Handle invalid rho values\n",
    "        \n",
    "        # Step 6: Variance of shock (sigma_xi^2)\n",
    "        shocks_boot = bootstrap_sample['residuals'] - rho_boot * bootstrap_sample['lagged_residuals']\n",
    "        sigma_xi_squared_samples.append(np.var(shocks_boot, ddof=1))\n",
    "    \n",
    "    # Calculate confidence intervals for each parameter\n",
    "    results = {\n",
    "        \"sigma_alpha_squared\": confidence_interval(sigma_alpha_squared_samples),\n",
    "        \"sigma_nu_squared\": confidence_interval(sigma_nu_squared_samples),\n",
    "        \"rho\": confidence_interval(rho_samples),\n",
    "        \"sigma_y_p0_squared\": confidence_interval(sigma_y_p0_squared_samples),\n",
    "        \"sigma_xi_squared\": confidence_interval(sigma_xi_squared_samples),\n",
    "    }\n",
    "    \n",
    "    # Print the results for the current group\n",
    "    print(f\"Bootstrap Confidence Intervals for {label}:\")\n",
    "    for param, (lower, upper) in results.items():\n",
    "        print(f\"{param}: 95% CI = ({lower:.4f}, {upper:.4f})\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"/Users/bishmaybarik/Library/CloudStorage/OneDrive-ShivNadarInstitutionofEminence/estimate_inc_risk/03_results/caste_group_results.txt\"\n",
    "\n",
    "# Open the file in append mode\n",
    "with open(output_path, \"a\") as file:  # Use \"a\" to append to the existing file\n",
    "    # Loop over each social group\n",
    "    for group, label in social_groups.items():\n",
    "        # Filter data for the current group\n",
    "        group_data = trimmed_data[trimmed_data['interest_soc_group'] == group]\n",
    "        \n",
    "        # Arrays to store bootstrap estimates\n",
    "        sigma_alpha_squared_samples = []\n",
    "        sigma_nu_squared_samples = []\n",
    "        rho_samples = []\n",
    "        sigma_y_p0_squared_samples = []\n",
    "        sigma_xi_squared_samples = []\n",
    "        \n",
    "        # Bootstrapping\n",
    "        for i in range(n_iterations):\n",
    "            # Resample the data with replacement\n",
    "            bootstrap_sample = resample(group_data, n_samples=n_size, replace=True)\n",
    "            \n",
    "            # Step 1: Recalculate total_income and residuals\n",
    "            X_boot = sm.add_constant(bootstrap_sample['age_yrs'])  # Add constant for intercept\n",
    "            y_boot = bootstrap_sample['log_total_income']\n",
    "            ols_model_boot = sm.OLS(y_boot, X_boot).fit()\n",
    "            bootstrap_sample['fitted_values'] = ols_model_boot.fittedvalues\n",
    "            bootstrap_sample['residuals'] = y_boot - bootstrap_sample['fitted_values']\n",
    "            \n",
    "            # Step 2: Variance of alpha (sigma_alpha^2)\n",
    "            sigma_alpha_squared_samples.append(np.var(bootstrap_sample['fitted_values'], ddof=1))\n",
    "            \n",
    "            # Step 3: Variance of transitory income (sigma_nu^2)\n",
    "            sigma_nu_squared_samples.append(np.var(bootstrap_sample['residuals'], ddof=1))\n",
    "            \n",
    "            # Step 4: Autoregressive parameter (rho)\n",
    "            bootstrap_sample['lagged_residuals'] = bootstrap_sample['residuals'].shift(1)\n",
    "            bootstrap_sample = bootstrap_sample.dropna()  # Drop rows with NaN due to lag\n",
    "            X_lag_boot = sm.add_constant(bootstrap_sample['lagged_residuals'])\n",
    "            y_res_boot = bootstrap_sample['residuals']\n",
    "            ar_model_boot = sm.OLS(y_res_boot, X_lag_boot).fit()\n",
    "            rho_samples.append(ar_model_boot.params['lagged_residuals'])\n",
    "            \n",
    "            # Step 5: Variance of permanent income at t=0 (sigma_y_p0^2)\n",
    "            rho_boot = ar_model_boot.params['lagged_residuals']\n",
    "            if abs(rho_boot) < 1:\n",
    "                sigma_y_p0_squared_samples.append(np.var(bootstrap_sample['fitted_values'], ddof=1) / (1 - rho_boot**2))\n",
    "            else:\n",
    "                sigma_y_p0_squared_samples.append(np.nan)  # Handle invalid rho values\n",
    "            \n",
    "            # Step 6: Variance of shock (sigma_xi^2)\n",
    "            shocks_boot = bootstrap_sample['residuals'] - rho_boot * bootstrap_sample['lagged_residuals']\n",
    "            sigma_xi_squared_samples.append(np.var(shocks_boot, ddof=1))\n",
    "        \n",
    "        # Calculate confidence intervals for each parameter\n",
    "        results = {\n",
    "            \"sigma_alpha_squared\": confidence_interval(sigma_alpha_squared_samples),\n",
    "            \"sigma_nu_squared\": confidence_interval(sigma_nu_squared_samples),\n",
    "            \"rho\": confidence_interval(rho_samples),\n",
    "            \"sigma_y_p0_squared\": confidence_interval(sigma_y_p0_squared_samples),\n",
    "            \"sigma_xi_squared\": confidence_interval(sigma_xi_squared_samples),\n",
    "        }\n",
    "        \n",
    "        # Write the results for the current group\n",
    "        file.write(f\"Bootstrap Confidence Intervals for {label}:\\n\")\n",
    "        for param, (lower, upper) in results.items():\n",
    "            file.write(f\"{param}: 95% CI = ({lower:.4f}, {upper:.4f})\\n\")\n",
    "        file.write(\"-\" * 50 + \"\\n\")\n",
    "\n",
    "print(f\"Bootstrap results successfully appended to {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
